---
compatible_cuba_versions: 7.0+
compatible_java_versions: 8+
project_id: cuba-petclinic-testing-middleware
permalink: testing-middleware
---
= Middleware Testing in CUBA applications
:showtitle:
:sectlinks:
:sectanchors:
:page-navtitle: Middleware Testing in CUBA applications
:page-excerpt: In this guide you will learn how automated testing in a CUBA application works. In particular this guide deals with middleware layer of a CUBA application and how tests can be executed there.
:page-root: ../../../
:project_id: cuba-petclinic-testing-middleware
:java_version: 1.8
:cuba_version: 7.0
:page-icone: images/intro-to-reports/guide_icone.svg

Test automation is key to every successful application development effort since it normally gives a high positive return on investment for QA efforts. CUBA applications are build on the Java ecosystem, which has a very powerful and mature test automation capabilities. In this guide you will learn how to leverage those capabilities.

First you will understand how testing in general works in a CUBA application. Afterwards this guide will concentrate on the area of unit & integration testing on the middleware layer.

== What Will be Built

This guide enhances the https://github.com/cuba-platform/cuba-petclinic[CUBA Petclinic] example to show how existing features can be automatically tested:

* automatic creation of a Visit for a given Pet Identification Number
* automatic "Disease Warning Mailing" for endangered pets
* calculation of next regular checkup date proposals for a Pet

=== Final Application

++++
<a href="https://raw.githubusercontent.com/cuba-guides/cuba-petclinic-intro-to-reports/master/img/adjustments-cuba-petclinic-overview.gif"><img src="https://raw.githubusercontent.com/cuba-guides/cuba-petclinic-intro-to-reports/master/img/login-screen.png"/></a>
++++

include::includes/guide_requirements.adoc[]

include::includes/petclinic_introduction.adoc[]

== Overview

Test automation is a commonly known best practice in the industry of software development since multiple decades. It allows to write a small test application, that executes a particular sub part of the production application and verifies its correct behavior.

In the Java ecosystem test automation has a long tradition. One famous example of this is the testing framework JUnit, which was one of the very first testing frameworks out in the market.

In a CUBA application, just like any other Java application, it is possible and recommended to write automated tests, that exercise parts of the target application.

In a test case (which is expressed as another Java class in a special test source directory) instances of production classes are instantiated and methods are executed. Afterwards the results are verified through programmatic comparison of an expected result against the actual result. Depending on this comparison, the test case is either treated as "success" or "failure".


A CUBA application is divided into two parts: the middleware part and the frontend part. The middleware consists of a combination of the `core` and the `global` module in the source code. It normally contains the majority of the business logic, integrations to other systems and the database related interactions.


TIP: This guide is only about testing the middleware part of a CUBA application, since for the frontend different patterns and testing strategies apply and therefore is covered in a dedicated guide.

== Test Environments
Depending on how production code is executed in a test environment, this environment needs to fulfil certain criteria. E.g. if testing a production class that interacts with a database, this database has to be up and running in that environment and the production code needs to have a proper connection to it.

If on the other hand a business logic in the application like a sum building over a couple of order items is exercised in a test case the execution environment can be much simpler and does not need to have dependencies on other parts.

When it comes to the CUBA middleware both of those environment scenarios can be instantiated in order to execute test classes. The first variant with running dependencies like a database is normally referred to as an `Integration test`. For the scenario where the production class is instantiated without any surrounding environment support is called a `Unit test`.

In the next section you will learn about the differences of those two environment types. Afterwards those environments are put in place with testing the two scenarios for the petclinic application.

=== Middleware Integration Testing

In this environment the production application is started partially. The integration test environment for a CUBA middleware is oftentimes the more common way of running a test case. This means that all the CUBA platform classes work the way you would expect them to work.

The `DataManager` interface for example, when invoking `dataManager.load(Customer.class).id(123).one()` will actually go against the database and fetch the customer with the ID 123. The same is true for the production code that was written in your application: `CustomerCreationService` will when interacting try to create a Customer in the database.

The integration testing environment has the following characteristics available:

* Spring application context
* Connection to external database
* Platform APIs work as in production codes

In order to make that environment available to the test case it take a couple of seconds to execute the test case.

==== Database Connection

CUBA uses the same database connection, that is established when running the production application. In the case of HSQLDB CUBA Studio takes care of having the database running when executing the test case.

By default the database instance is `shared` between the test environment and the situation when you run the application locally. This means that data that is defined locally when running the application is also available in the test case execution. Furthermore, if the test case changes data in the database, it is also changed the next time when you start the application.

WARNING: Sharing data between the two environments is convenient and can often be helpful but also can cause some level of non-determinism. In case you are facing the situation of having problems expressing the correct assertions in the test case, because you cannot reliably determine how much / which data is in the database or you accidentally change data through the test case, it is also possible to split the databases of the two environments to avoid this behavior.

==== Test Container

The Test container is an object in the test case, that is mainly responsible for starting up and managing the integration test environment. It is supposed to be used in the test class as an object that when starting the test case will do various things to spin up the environment:

* start the Spring application context
* establishes a DB connection
* instantiates all CUBA platform APIs
* activates all application components and their configuration

An example usage of this Test Container looks like this:

.SampleIntegrationTest.java
[source,java]
----
@ExtendWith(PetclinicTestContainer.Common.class) // <1>
public class SampleIntegrationTest {

    public static PetclinicTestContainer testContainer =
            PetclinicTestContainer.Common.INSTANCE; // <2>

    @Test
    public void persistenceAPI_canBeRetrieved_fromTheTestContainer() {

        Persistence persistence = testContainer.persistence(); // <3>

        assertNotNull(persistence);
    }
}
----
<1> the JUnit integration test uses the PetclinicTestContainer Extension
<2> the petclinic test container instance is added as a field in the test class
<3> in the test cases the container can be used to interact with the test environment

TIP: This guide uses JUnit as the testing library for examples. CUBA supports multiple testing frameworks like Spock, but by default it ships with JUnit.

=== Middleware Unit Testing

Besides the integration test environment it is also possible to create test cases, that do not spin up the Spring application context or any CUBA platform APIs at all. As for the above described use case, where there are no dependencies to the environment that should be leveraged in the test case, not having to start the environment is oftentimes beneficial.

The two main benefits of writing unit test in an isolated fashion without an integration test environment are:

* locality of the test scenario
* test execution speed

In this case the class under test is instantiated directly. Since dependency injection is not working in this scenario potential dependencies (objects that the class under test relies upon) have to be instantiated manually and passed into the class under test directly. In case those dependencies are CUBA APIs, they normally have to be mocked. Mocking is a common way in test automation that helps to emulate / control certain external parts that the system under test interacts with in order to isolate the test subject as much as possible from its outside world.

==== Mocking


== Tests for Petclinic Functionality

In the next section you will learn how to put all this theory into action by implementing unit / integration test cases, that verify the correct
behavior of features that have been introduced in the https://www.cuba-platform.com/guides/intro-working-with-data-in-cuba[Working with Data in CUBA] guide next to new functionality that you will learn about later.

=== Automatic Visit Creation

The first test case is about the automatic visit creation functionality of the Petclinic application. In the Visit browse screen, the user
can create a new visit by entering the Pet Identification Number as a quick action. The software will go ahead and create a visit
for todays date for the entered Pet.

Part of the implementation of the feature is a CUBA service called `VisitService` that is triggered from the UI. It contains one method `Visit createVisitForToday(String identificationNumber)` that is the subject of the test case.

WARNING: Although the feature includes a UI part, this will not be part of the automated testing. It is quite common to test certain sub parts of the implementation in isolation (as you will see). That being said, there is still a need for a real end-to-end test case to verify all the parts work together correctly. But this is out of scope for this guide.


==== Test Class Setup

In order to implement the defined test case, first let's look at the integration test harness of the test case. It is based
on the description of the `SampleIntegrationTest` from above. In this test there are some noteworthy additions to simplify
the test cases.

.VisitServiceTest.java
[source,java]
----
@ExtendWith(PetclinicTestContainer.Common.class)
public class VisitServiceTest {
  public static PetclinicTestContainer testContainer = PetclinicTestContainer.Common.INSTANCE;
  private static VisitService visitService; // <1>
  private static PetclinicVisitDb db;

  private Visit visit;
  private Pet pikachu;

  @BeforeAll
  public static void setupEnvironment() {
    visitService = AppBeans.get(VisitService.class);

    db = new PetclinicVisitDb( // <2>
        AppBeans.get(DataManager.class),
        testContainer
    );
  }

  @BeforeEach
  public void loadPikachu() { // <3>
    pikachu = db.petWithName("Pikachu", "pet-with-owner-and-type");
  }

  // different test cases...

  @AfterEach
  public void cleanupVisit() { // <4>
    db.remove(visit);
  }
}
----
<1> the `VisitService` is the system under test (SUT) in this test case
<2> the `PetclinicVisitDb` variable acts as an abstraction for holding all relevant interactions with the database (setup test data, data verification)
<3> `loadPikachu` is one example of a method that should be executed before each test case in this class
<4> the `cleanupVisit` does the data cleanup in the DB after each test case

The JUnit Annotations `@BeforeEach` and `@AfterEach` are used in order to execute certain parts of the code before / after
each test case.


==== Arrange Act Assert

The general pattern of how the most test cases in this guide are defined is called `Arrange-Act-Assert`:

First there is a phase of test data setup or verification of test data (`Arrange`). This is necessary to ensure the test case has a stable set of test
data to start from. Next the implementation is exercised with the desired input parameters (`Act`). In the last phase, the verifications
are executed to see if the code changed the system in the desired ways (`Assert`).


==== Test Utility Methods

One important piece here is the class `PetclinicVisitDb` and its usage via the `db` variable.
This class encapsulated Database interactions that is tailored towards the test class `VisitServiceTest`.

It has the following API:

.PetclinicVisitDb.java
[source,java]
----
public class PetclinicVisitDb {

  public Pet petWithName(String name, String view) { /* ... */ }

  public void remove(Entity<UUID> entity) { /* ... */ }

  public Optional<Pet> petWithIdentificationNumber(
          String identificationNumber
  ) { /* ... */ }

  public Long countVisitsFor(Pet pet) { /* ... */ }

  public Long countVisits() { /* ... */ }

}
----

Under the hood the class interacts with the `dataManager` and other various things in order to provide this specific
API to the test cases. Also this class sits in the test sources, next to the test class. This class is a combination of
an implementation of the http://xunitpatterns.com/Test%20Utility%20Method.html[Test Utility Method pattern] and the
 http://xunitpatterns.com/Back%20Door%20Manipulation.html[Back Door Manipulation Pattern].

It is not strictly necessary to put this logic into a dedicated class, but it oftentimes frees up the test classes from various
helper methods or inline code that will increase the noise in the test case itself.


==== First Test Case

Before looking into the first test case, here is a recap of what the `VisitService` is doing in the implementation:

1. it looks up the Pet by the given Identification Number
a. in case the Pet is found it will use it
b. in case no Pet is found, it will not create a Visit
2. it creates a new instance of a Visit with the correct attributes
a. it figures out the correct Pet and assigns it to the Visit
b. it uses `today` as the `visitDate`
3. it stores the newly created Visit

Based on that description it is possible to identify a couple of test cases, that describe the above mentioned behavior:

1. `createsANewVisit_forTheCorrectPet` - verifies `1.a`, `2.a` and `3.`
2. `createsANewVisit_withTheCorrectVisitInformation` - verifies `1.a`, `2.b` and `3.`
3. `createsNoVisit_forAnIncorrectIdentificationNumber` - verifies `1.b`

Let's look into the test case which checks for the correct Pet to be associated to the new Visit:

.VisitServiceTest.java
[source,java]
----
class VisitServiceTest {
    // ...
  private Visit visit;
  private Pet pikachu;

  @BeforeEach
  public void loadPikachu() {
    pikachu = db.petWithName("Pikachu", "pet-with-owner-and-type");
  }

  @Test
  public void createVisitForToday_createsANewVisit_forTheCorrectPet() { // <1>
    // given: there is one visit associated to pikachu
    assertThat(db.countVisitsFor(pikachu))
        .isEqualTo(1);
    // when: logic is executed for the pikachus identification number
    visit = visitService.createVisitForToday(
            pikachu.getIdentificationNumber()
    );
    // then: there are two visits associated to pikachu
    assertThat(db.countVisitsFor(pikachu)) // <2>
        .isEqualTo(2);
  }
}
----
<1> the method name of the JUnit test case describes the high level narrative of the test case
<2> the assertions are expressed through a corresponding AssertJ assertion

As described above the test case uses the `Arrange-Act-Assert` pattern with the three steps, that are described through
the `given`, `when` and `then` comments in the test case.

With the passing in of the Identification Number of Pikachu, and then afterwards assert that the count of visits was
increased in the DB it is safe to say, that the `VisitService` correctly did a lookup from the Identification Number to
the correct Pet entity (`1.a`).

Furthermore we can conclude that `2.a` and `3.` are also handled correctly since in the
assertion we do another DB lookup of visits by the foreign key to the pikachu Pet instance and verify the amount was
increased exactly by one.

==== Database Seed Data
One thing to note here is that there is already data in the database. Not only Pets like `Pikachu` are already stored,
but furthermore Visit information are already stored. This is due to the fact that in the Petclinic application
the `30.create-db.sql` file contains seed data that is used for demonstration purposes.
This has some upsides as well as downsides when it comes to test automation.

On the one side it makes the test data setup easier, as there are already some data to rely upon.
It is not necessary to programmatically create  the required `Pet`, `PetType` and `Visit` entities
before any test case can be executed. This make the test creation easier and faster.

On the other side, relying on test data that is defined outside the test case also comes with a maintenance cost.
It generally makes the test cases less resilient to changes of that test data. Since this is central test data
that all test cases share (as well as the running application), this situation can be even worse.

To mitigate that situation the first test case contains the precondition assertion:
`assertThat(db.countVisitsFor(pikachu)).isEqualTo(1);`. It ensures that the test data setup is what the test expect
in order to function correctly. In case this precondition is not given, the test will fail immediately pointing
to that problem. Without this precondition a downstream error would have occurred and it would be harder to determine
the root cause of the failing test case.

It is also possible to improve the situation even further but still stay with central test data setup.
In fact for the the test case it is irrelevant of there are 1, 2 or 85 visits in the database for the pet.
The only thing that is relevant is that the amount should have been increased exactly by one.

To make the test more independent on the amount of `Visit` data, the test can capture the amount before the execution like this:

[source,java]
----
class VisitServiceTest {
  @Test
  public void createVisitForToday_createsANewVisit_forTheCorrectPet() {
    // given: the amount of visits for pikachu is captured
    Long visitAmountBefore = db.countVisitsFor(pikachu);
    // when: logic is executed for the pikachus identification number
    visit = visitService.createVisitForToday(
            pikachu.getIdentificationNumber()
    );
    // then: there is one more visit associated to pikachu
    assertThat(db.countVisitsFor(pikachu))
        .isEqualTo(visitAmountBefore + 1);
  }
}
----

With that change the test will always pass independent on how many visits for pikachu are inserted by the environment.


==== Other Test Cases for CreateVisitForToday

For this example the two additional test cases will not be discussed in this guide as they are quite similar compared
to the test case from above. Instead you can look them up in the corresponding example project:

* https://github.com/cuba-guides/cuba-petclinic-testing-middleware/blob/master/modules/core/test/com/haulmont/sample/petclinic/service/visit/create_visit/VisitServiceTest.java#L65[test case: createVisitForToday_createsANewVisit_withTheCorrectVisitInformation]
* https://github.com/cuba-guides/cuba-petclinic-testing-middleware/blob/master/modules/core/test/com/haulmont/sample/petclinic/service/visit/create_visit/VisitServiceTest.java#L85[test case: createVisitForToday_createsNoVisit_forAnIncorrectIdentificationNumber]

=== Disease Warning Mailing

=== Next Regular Checkup Date Proposal

== Summary


== Further Information

* https://doc.cuba-platform.com/reporting-7.0/index.html[CUBA docs: Reporting]
* https://doc.cuba-platform.com/reporting-7.1/open_office.html[CUBA docs: Reporting - Appendix A: Installing and Configuring OpenOffice]
