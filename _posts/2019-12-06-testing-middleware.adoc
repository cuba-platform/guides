---
compatible_cuba_versions: 7.0+
compatible_java_versions: 8+
project_id: cuba-petclinic-testing-middleware
permalink: testing-middleware
---
= Middleware Testing in CUBA applications
:showtitle:
:sectlinks:
:sectanchors:
:page-navtitle: Middleware Testing in CUBA applications
:page-excerpt: In this guide you will learn how automated testing in a CUBA application works. In particular this guide deals with middleware layer of a CUBA application and how tests can be executed there.
:page-root: ../../../
:project_id: cuba-petclinic-testing-middleware
:java_version: 1.8
:cuba_version: 7.0
:page-icone: images/intro-to-reports/guide_icone.svg

Test automation is key to every successful application development effort since it gives a high positive return on investment for QA efforts. CUBA applications are build on the Java ecosystem, which has a very powerful and mature test automation capabilities. In this guide you will learn how to leverage those capabilities.

First you will understand how testing in general works in a CUBA application. Afterwards this guide will concentrate on the area of unit & integration testing on the middleware layer.

== What Will be Built

This guide enhances the https://github.com/cuba-platform/cuba-petclinic[CUBA Petclinic] example to show how existing features can be automatically tested:

* automatic creation of a Visit for a given Pet Identification Number
* automatic "Disease Warning Mailing" for endangered pets
* calculation of next regular checkup date proposals for a Pet

=== Final Application

++++
<a href="https://raw.githubusercontent.com/cuba-guides/cuba-petclinic-intro-to-reports/master/img/adjustments-cuba-petclinic-overview.gif"><img src="https://raw.githubusercontent.com/cuba-guides/cuba-petclinic-intro-to-reports/master/img/login-screen.png"/></a>
++++

include::includes/guide_requirements.adoc[]

include::includes/petclinic_introduction.adoc[]

== Overview

Test automation is a commonly known best practice in the industry of software development since multiple decades. It allows to write a small test application, that executes a particular sub part of the production application and verifies its correct behavior.

In the Java ecosystem test automation has a long tradition. One famous example of this is the testing framework JUnit, which was one of the very first testing frameworks out in the market.

In a CUBA application, just like any other Java application, it is possible and recommended to write automated tests, that exercise parts of the target application.

In a test case (which is expressed as another Java class in a special test source directory) instances of production classes are instantiated and methods are executed. Afterwards the results are verified through programmatic comparison of an expected result against the actual result. Depending on this comparison, the test case is either treated as "success" or "failure".


A CUBA application is divided into two parts: the middleware part and the frontend part. The middleware consists of a combination of the `core` and the `global` module in the source code. It normally contains the majority of the business logic, integrations to other systems and the database related interactions.


TIP: This guide is only about testing the middleware part of a CUBA application, since for the frontend different patterns and testing strategies apply and therefore is covered in a dedicated guide.

== Test Environments
Depending on how production code is executed in a test environment, this environment needs to fulfil certain criteria. E.g. if testing a production class that interacts with a database, this database has to be up and running in that environment and the production code needs to have a proper connection to it.

If on the other hand a business logic in the application like a sum building over a couple of order items is exercised in a test case the execution environment can be much simpler and does not need to have dependencies on other parts.

When it comes to the CUBA middleware both of those environment scenarios can be instantiated in order to execute test classes. The first variant with running dependencies like a database is normally referred to as an `Integration test`. For the scenario where the production class is instantiated without any surrounding environment support is called a `Unit test`.

In the next section you will learn about the differences of those two environment types. Afterwards those environments are put in place with testing the two scenarios for the petclinic application.

=== Middleware Integration Testing

In this environment the production application is started partially. The integration test environment for a CUBA middleware is oftentimes the more common way of running a test case. This means that all the CUBA platform classes work the way you would expect them to work.

The `DataManager` interface for example, when invoking `dataManager.load(Customer.class).id(123).one()` will actually go against the database and fetch the customer with the ID 123. The same is true for the production code that was written in your application: `CustomerCreationService` will when interacting try to create a Customer in the database.

The integration testing environment has the following characteristics available:

* Spring application context
* Connection to external database
* Platform APIs work as in production codes

In order to make that environment available to the test case it take a couple of seconds to execute the test case.

==== Database Connection

CUBA uses the same database connection, that is established when running the production application. In the case of HSQLDB CUBA Studio takes care of having the database running when executing the test case.

By default the database instance is `shared` between the test environment and the situation when you run the application locally. This means that data that is defined locally when running the application is also available in the test case execution. Furthermore, if the test case changes data in the database, it is also changed the next time when you start the application.

WARNING: Sharing data between the two environments is convenient and can often be helpful but also can cause some level of non-determinism. In case you are facing the situation of having problems expressing the correct assertions in the test case, because you cannot reliably determine how much / which data is in the database or you accidentally change data through the test case, it is also possible to split the databases of the two environments to avoid this behavior.

==== Test Container

The Test container is an object in the test case, that is mainly responsible for starting up and managing the integration test environment. It is supposed to be used in the test class as an object that when starting the test case will do various things to spin up the environment:

* start the Spring application context
* establishes a DB connection
* instantiates all CUBA platform APIs
* activates all application components and their configuration

An example usage of this Test Container looks like this:

.SampleIntegrationTest.java
[source,java]
----
@ExtendWith(PetclinicTestContainer.Common.class) // <1>
public class SampleIntegrationTest {

    public static PetclinicTestContainer testContainer =
            PetclinicTestContainer.Common.INSTANCE; // <2>

    @Test
    public void persistenceAPI_canBeRetrieved_fromTheTestContainer() {

        Persistence persistence = testContainer.persistence(); // <3>

        assertNotNull(persistence);
    }
}
----
<1> the JUnit integration test uses the PetclinicTestContainer Extension
<2> the petclinic test container instance is added as a field in the test class
<3> in the test cases the container can be used to interact with the test environment

TIP: This guide uses JUnit as the testing library for examples. CUBA supports multiple testing frameworks like Spock, but by default it ships with JUnit.

=== Middleware Unit Testing

Besides the integration test environment it is also possible to create test cases, that do not spin up the Spring application context or any CUBA platform APIs at all. As for the above described use case, where there are no dependencies to the environment that should be leveraged in the test case, not having to start the environment is oftentimes beneficial.

The two main benefits of writing unit test in an isolated fashion without an integration test environment are:

* locality of the test scenario
* test execution speed

In this case the class under test is instantiated directly. Since dependency injection is not working in this scenario potential dependencies (objects that the class under test relies upon) have to be instantiated manually and passed into the class under test directly. In case those dependencies are CUBA APIs, they normally have to be mocked. Mocking is a common way in test automation that helps to emulate / control certain external parts that the system under test interacts with in order to isolate the test subject as much as possible from its outside world.

==== Mocking


== Tests for Petclinic Functionality

In the next section you will learn how to put all this theory into action by implementing unit / integration test cases, that verify the correct
behavior of features that have been introduced in the https://www.cuba-platform.com/guides/intro-working-with-data-in-cuba[Working with Data in CUBA] guide next to new functionality that you will learn about later.

=== Automatic Visit Creation

The first test case is about the automatic visit creation functionality of the Petclinic application. In the Visit browse screen, the user
can create a new visit by entering the Pet Identification Number as a quick action. The software will go ahead and create a visit
for todays date for the entered Pet.

Part of the implementation of the feature is a CUBA service called `VisitService` that is triggered from the UI. It contains one method `Visit createVisitForToday(String identificationNumber)` that is the subject of the test case.

WARNING: Although the feature includes a UI part, this will not be part of the automated testing. It is quite common to test certain sub parts of the implementation in isolation (as you will see). That being said, there is still a need for a real end-to-end test case to verify all the parts work together correctly. But this is out of scope for this guide.

Before looking into the concrete test case, here is a recap of what the `VisitService` is doing in the implementation:

1. it looks up the Pet by the given Identification Number
a. in case the Pet is found it will use it
b. in case no Pet is found, it will not create a Visit
2. it creates a new instance of a Visit with the correct attributes
a. it figures out the correct Pet and assigns it to the Visit
b. it uses `today` as the `visitDate`
3. it stores the newly created Visit


A general test case that exercises the implementation and verifies its behavior looks like this:

.VisitServiceTest.java
[source,java]
----
public class VisitServiceTest {
    // ...
    @Test
    public void createVisitForToday_createsANewVisit_forTheCorrectPet() {
        // given: verify DB contains one visit for Pikachu (precondition)
        assertThat(db.countVisitsFor(pikachu))
            .isEqualTo(1);
        // when: a new visit is created for Pikachus Identification Number
        visit = visitService.createVisitForToday(
                pikachu.getIdentificationNumber()
        );
        // then: DB contains two visits for Pikachu (verification)
        assertThat(db.countVisitsFor(pikachu))
            .isEqualTo(2);
    }
}
----

This test case already lays out the general pattern of how the most test cases in this guide are defined. The pattern is called `Arrange-Act-Assert`:

First there is a phase of test data setup or verification of test data (`Arrange`). This is necessary to ensure the test case has a stable set of test
data to start from. Next the implementation is exercised with the desired input parameters (`Act`). In the last phase, the verifications
are executed to see if the code changed the system in the desired ways (`Assert`).


Based on that description it is possible to identify a couple of test cases, that describe the above mentioned behavior:

* `createVisitForToday_createsANewVisit_forTheCorrectPet` - verifies `1.a`, `2.a` and `3.`
* `createVisitForToday_createsANewVisit_withTheCorrectVisitInformation` - verifies `1.a`, `2.b` and `3.`
* `createVisitForToday_createsNoVisit_forAnIncorrectIdentificationNumber` - verifies `1.b`


==== Test class setup

For this test class

.VisitServiceTest.java
[source,java]
----
@ExtendWith(PetclinicTestContainer.Common.class)
public class VisitServiceTest {


  public static PetclinicTestContainer testContainer = PetclinicTestContainer.Common.INSTANCE;

  private static TimeSource timeSource;
  private static VisitService visitService;

  private static PetclinicVisitDb db;

  private Visit visit;
  private Pet pikachu;

  @BeforeAll
  public static void setupEnvironment() {
    visitService = AppBeans.get(VisitService.class);

    timeSource = AppBeans.get(TimeSource.class);

    db = new PetclinicVisitDb(
        AppBeans.get(DataManager.class),
        testContainer
    );
  }

  @BeforeEach
  public void loadPikachu() {
    pikachu = db.petWithName("Pikachu", "pet-with-owner-and-type");
  }

  @Test
  public void createVisitForToday_createsANewVisit_forTheCorrectPet() {

    // given:
    assertThat(db.countVisitsFor(pikachu)).isEqualTo(1);

    // when:
    visit = visitService.createVisitForToday(pikachu.getIdentificationNumber());

    // then:
    assertThat(db.countVisitsFor(pikachu)).isEqualTo(2);
  }

  @Test
  public void createVisitForToday_createsANewVisit_withTheCorrectVisitInformation() {

    // given:
    assertThat(db.countVisitsFor(pikachu)).isEqualTo(1);

    // when:
    visit = visitService.createVisitForToday(pikachu.getIdentificationNumber());

    // then:
    assertThat(visit.getPet())
        .isEqualTo(pikachu);

    // and:
    assertThat(visit.getVisitDate())
        .isInSameDayAs(timeSource.currentTimestamp());

  }

  @Test
  public void createVisitForToday_createsNoVisit_forAnIncorrectIdentificationNumber() {

    // given:
    String incorrectIdentificationNumber = "IncorrectIdentificationNumber";

    assertThat(db.petWithIdentificationNumber(incorrectIdentificationNumber))
        .isNotPresent();

    // and:
    Long amountOfVisitsBefore = db.countVisits();

    // when:
    visit = visitService.createVisitForToday(incorrectIdentificationNumber);

    // then:
    assertThat(visit)
        .isNull();

    // and:
    assertThat(db.countVisits())
        .isEqualTo(amountOfVisitsBefore);
  }

  @AfterEach
  public void cleanupVisit() {
    db.remove(visit);
  }

}
----
<1> the JUnit integration test uses the PetclinicTestContainer Extension
<2> the petclinic test container instance is added as a field in the test class
<3> in the test cases the container can be used to interact with the test environment



=== Disease Warning Mailing

=== Next Regular Checkup Date Proposal

== Summary


== Further Information

* https://doc.cuba-platform.com/reporting-7.0/index.html[CUBA docs: Reporting]
* https://doc.cuba-platform.com/reporting-7.1/open_office.html[CUBA docs: Reporting - Appendix A: Installing and Configuring OpenOffice]
